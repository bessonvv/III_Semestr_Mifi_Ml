# Сессионное задание. Трек 1. Обучение с подкреплением
---

### Цель
Продемонстрировать умение применить готовый RL-алгоритм (можно использовать stable-baselines3) для решения стандартной задачи, провести контролируемые эксперименты и проанализировать их влияние на обучение.
В результате исследования установлено, что DQN baseline лучше справился с задачей управлением агентом

![График обучения](https://github.com/bessonvv/III_Semestr_Mifi_Ml/blob/main/Трек%201.%20Обучение%20с%20подкреплением/Session_Task/plot.png)

Описание файлов:

 - RL Session.ipynb - основной файл сессионного задания;

 - qn_baseline_demo.mp4 - Видео демонстрация работы лучшего алгоритма после обучения;

 - После запуска всех ячеек будет сформирована папка runs с весами для каждого алгоритма.
