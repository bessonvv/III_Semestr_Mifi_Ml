{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Аналитическая система эпидемиологического мониторинга COVID-19\n",
        "\n",
        "**Цель проекта:** Разработать аналитическую систему для эпидемиологического мониторинга COVID-19 на основе метаданных рентгеновских снимков, используя стек PySpark.\n",
        "\n",
        "**Датасет:** COVID-19 Chest X-Ray Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Подготовка окружения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf, when, lit, regexp_replace, count, median, lower, sum as _sum, year, month, row_number\n",
        "from pyspark.sql.types import StructType, StructField, StringType, LongType, DateType\n",
        "from pyspark.sql.window import Window\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Настройка окружения\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
        "\n",
        "# Создание Spark сессии\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"COVID-19 Эпидемиологический мониторинг\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Загрузка и изучение данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка данных\n",
        "df = spark.createDataFrame(\n",
        "    pd.read_csv('https://raw.githubusercontent.com/ieee8023/covid-chestxray-dataset/master/metadata.csv')\n",
        "    .replace({np.nan: None})[['patientid', 'age', 'sex', 'finding', 'view', 'date']]\n",
        ")\n",
        "\n",
        "df.printSchema()\n",
        "df.show(5, False)\n",
        "print(f'\\nВсего записей: {df.count()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Анализ качества данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Подсчет пропущенных значений\n",
        "results = []\n",
        "for column in df.columns:\n",
        "    cnt_null = df.select(_sum(when(col(column).isNull(), lit(1)).otherwise(lit(0)))).collect()[0][0]\n",
        "    results.append((column, cnt_null))\n",
        "\n",
        "df_null = pd.DataFrame(results, columns=[\"name_col\", \"cnt_null\"])\n",
        "\n",
        "# Визуализация пропущених значень\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(df_null['name_col'], df_null['cnt_null'])\n",
        "plt.xlabel('Количество пропущенных значений')\n",
        "plt.ylabel('Название колонки')\n",
        "plt.title('Распределение пропущенных значений по полям')\n",
        "plt.tight_layout()\n",
        "\n",
        "for bar in bars:\n",
        "    width = bar.get_width()\n",
        "    plt.text(width, bar.get_y() + bar.get_height()/2, f' {int(width)}', va='center', ha='left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Анализ аномалий в возрасте\n",
        "age_data = df.select(regexp_replace(col('age'), ',', '.').cast('float').alias('age')) \\\n",
        "    .where(col('age').isNotNull()).toPandas()['age']\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.boxplot(age_data.dropna(), vert=False)\n",
        "plt.title('Boxplot для анализа аномалий в возрасте')\n",
        "plt.xlabel('Возраст (лет)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "median_val = age_data.median()\n",
        "q1 = age_data.quantile(0.25)\n",
        "q3 = age_data.quantile(0.75)\n",
        "\n",
        "plt.axvline(x=median_val, color='red', linestyle='--', alpha=0.5, label=f'Медиана: {median_val:.1f}')\n",
        "plt.axvline(x=q1, color='green', linestyle=':', alpha=0.5, label=f'Q1: {q1:.1f}')\n",
        "plt.axvline(x=q3, color='blue', linestyle=':', alpha=0.5, label=f'Q3: {q3:.1f}')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f'Всего записей з віком: {len(age_data)}')\n",
        "print(f'Пропущено: {df.where(col(\"age\").isNull()).count()}')\n",
        "\n",
        "iqr = q3 - q1\n",
        "lower_bound = q1 - 1.5 * iqr\n",
        "upper_bound = q3 + 1.5 * iqr\n",
        "print(f'Количество выбросов: {len(age_data[(age_data < lower_bound) | (age_data > upper_bound) | (age_data < 0) | (age_data > 120)])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Предобработка данных\n",
        "\n",
        "### 4.1. UDF для парсинга дат"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_date(date_str):\n",
        "    \"\"\"Функция для парсинга различных форматов дат\"\"\"\n",
        "    if not date_str:\n",
        "        return None\n",
        "    date_str = str(date_str).strip()\n",
        "    formats = [\n",
        "        \"%B %d, %Y\",      # January 22, 2020\n",
        "        \"%b %d, %Y\",      # Feb 18, 2020\n",
        "        \"%d %B %Y\",       # 12 March 2020\n",
        "        \"%d %b %Y\",       # 12 Mar 2020\n",
        "        \"%m/%d/%Y\",       # 3/3/2020\n",
        "        \"%m/%d/%y\",       # 03/16/20\n",
        "        \"%B %Y\",          # March 2003\n",
        "        \"%b %Y\",          # Mar 2003\n",
        "        \"%Y\",             # 2014\n",
        "        \"%B %d\",          # January 12\n",
        "        \"%b %d\",          # Feb 18\n",
        "        \"%d %B\",          # 12 March\n",
        "        \"%d %b\",          # 12 Mar\n",
        "    ]\n",
        "    \n",
        "    for fmt in formats:\n",
        "        try:\n",
        "            result = datetime.strptime(date_str, fmt).date()\n",
        "            if fmt in [\"%B %d\", \"%b %d\", \"%d %B\", \"%d %b\"]:\n",
        "                result = result.replace(year=2020)\n",
        "            return result\n",
        "        except:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "# Регистрация UDF\n",
        "parse_date_udf = udf(parse_date, DateType())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2. UDF для категоризации возраста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def categorize_age(age):\n",
        "    \"\"\"Функция для категоризации возраста\"\"\"\n",
        "    if age is None:\n",
        "        return \"Неизвестно\"\n",
        "    age = float(age)\n",
        "    if age < 18:\n",
        "        return \"0-17 (Дети)\"\n",
        "    elif age < 30:\n",
        "        return \"18-29 (Молодые)\"\n",
        "    elif age < 45:\n",
        "        return \"30-44 (Взрослые)\"\n",
        "    elif age < 60:\n",
        "        return \"45-59 (Средний возраст)\"\n",
        "    elif age < 75:\n",
        "        return \"60-74 (Пожилые)\"\n",
        "    else:\n",
        "        return \"75+ (Преклонный возраст)\"\n",
        "\n",
        "# Регистрация UDF\n",
        "categorize_age_udf = udf(categorize_age, StringType())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3. UDF для унификации диагнозов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def unify_finding(finding):\n",
        "    \"\"\"Функция для унификации диагнозов\"\"\"\n",
        "    if finding is None:\n",
        "        return \"Unknown\"\n",
        "    finding_str = str(finding).lower().strip()\n",
        "    \n",
        "    # COVID-19\n",
        "    if any(word in finding_str for word in [\"covid\", \"sars-cov-2\", \"coronavirus\", \"corona\"]):\n",
        "        return \"COVID-19\"\n",
        "    \n",
        "    # Пневмония\n",
        "    elif \"pneumonia\" in finding_str:\n",
        "        return \"Pneumonia\"\n",
        "    \n",
        "    # ARDS\n",
        "    elif \"ards\" in finding_str or \"acute respiratory distress\" in finding_str:\n",
        "        return \"ARDS\"\n",
        "    \n",
        "    # Нормально\n",
        "    elif any(word in finding_str for word in [\"no finding\", \"normal\", \"clear\"]):\n",
        "        return \"Normal\"\n",
        "    \n",
        "    # Туберкулез\n",
        "    elif \"tuberculosis\" in finding_str or \"tb\" in finding_str:\n",
        "        return \"Tuberculosis\"\n",
        "    \n",
        "    # Другое\n",
        "    else:\n",
        "        if \"/\" in finding_str:\n",
        "            return finding_str.split(\"/\")[0].strip().title()\n",
        "        elif len(finding_str) > 30:\n",
        "            return \"Other\"\n",
        "        else:\n",
        "            return finding_str.title()\n",
        "\n",
        "# Регистрация UDF\n",
        "unify_finding_udf = udf(unify_finding, StringType())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4. Применение предобработки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Заполнение пропусков в возрасте медианой\n",
        "median_age = df.where(col(\"age\").isNotNull()).agg(median(\"age\")).collect()[0][0]\n",
        "df = df.withColumn(\"age\", when(col(\"age\").isNull(), median_age).otherwise(col(\"age\")))\n",
        "\n",
        "# Заполнение пропусков в поле наиболее частым значением\n",
        "most_common_sex = df.where(col(\"sex\").isNotNull() & (col(\"sex\") != \"\")) \\\n",
        "    .groupBy(\"sex\").count().orderBy(col(\"count\").desc()).first()[0]\n",
        "df = df.withColumn(\"sex\", when(col(\"sex\").isNull(), most_common_sex).otherwise(col(\"sex\")))\n",
        "\n",
        "# Парсинг дат\n",
        "df = df.withColumn('date_parsed', parse_date_udf(col('date')))\n",
        "most_common_date = df.where(col('date_parsed').isNotNull()) \\\n",
        "    .groupBy('date_parsed').count().orderBy(col('count').desc()).first()[0]\n",
        "df = df.withColumn('date_correct', when(col('date_parsed').isNotNull(), col('date_parsed')).otherwise(most_common_date))\n",
        "\n",
        "# Категоризация возраста\n",
        "df = df.withColumn('age_category', categorize_age_udf(col('age')))\n",
        "\n",
        "# Унификация диагнозов\n",
        "df = df.withColumn('finding_unified', unify_finding_udf(col('finding')))\n",
        "\n",
        "# Удаление дубликатов\n",
        "df = df.dropDuplicates()\n",
        "\n",
        "# Удаление вспомогательных колонок\n",
        "df = df.drop('finding', 'date', 'date_parsed')\n",
        "\n",
        "print(\"Данные после предобработки:\")\n",
        "df.show(5, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. SQL-аналитика\n",
        "\n",
        "### Создание временного представления"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView('covid_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Базовая статистика по диагнозам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query1 = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        finding_unified,\n",
        "        COUNT(*) as count_patients,\n",
        "        ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER(), 2) as percentage,\n",
        "        ROUND(AVG(age), 1) as avg_age,\n",
        "        MIN(age) as min_age,\n",
        "        MAX(age) as max_age\n",
        "    FROM covid_data\n",
        "    GROUP BY finding_unified\n",
        "    ORDER BY count_patients DESC\n",
        "\"\"\")\n",
        "\n",
        "query1.show(20, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Распределение по полу и диагнозам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query2 = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        sex,\n",
        "        finding_unified,\n",
        "        COUNT(*) as count,\n",
        "        ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER (PARTITION BY sex), 2) as percentage_by_sex\n",
        "    FROM covid_data\n",
        "    GROUP BY sex, finding_unified\n",
        "    ORDER BY sex, count DESC\n",
        "\"\"\")\n",
        "\n",
        "query2.show(20, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Оконная функция - топ-3 по возрасту в каждой группе диагнозов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query3 = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        patientid,\n",
        "        age,\n",
        "        sex,\n",
        "        finding_unified,\n",
        "        rank_in_finding\n",
        "    FROM (\n",
        "        SELECT\n",
        "            patientid,\n",
        "            age,\n",
        "            sex,\n",
        "            finding_unified,\n",
        "            ROW_NUMBER() OVER (PARTITION BY finding_unified ORDER BY age DESC) as rank_in_finding\n",
        "        FROM (\n",
        "            SELECT DISTINCT\n",
        "                patientid,\n",
        "                age,\n",
        "                sex,\n",
        "                finding_unified\n",
        "            FROM covid_data\n",
        "        ) q\n",
        "    ) t\n",
        "    WHERE rank_in_finding <= 3\n",
        "    ORDER BY finding_unified, rank_in_finding\n",
        "\"\"\")\n",
        "\n",
        "query3.show(20, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Анализ временных трендов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query4 = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        YEAR(date_correct) as year,\n",
        "        MONTH(date_correct) as month,\n",
        "        COUNT(*) as count_studies,\n",
        "        COUNT(DISTINCT patientid) as unique_patients,\n",
        "        ROUND(AVG(age), 1) as avg_age\n",
        "    FROM covid_data\n",
        "    GROUP BY YEAR(date_correct), MONTH(date_correct)\n",
        "    ORDER BY year, month\n",
        "\"\"\")\n",
        "\n",
        "query4.show(20, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.5 Статистика по проекциям снимков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query5 = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        view,\n",
        "        finding_unified,\n",
        "        COUNT(*) as count_images,\n",
        "        ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER(PARTITION BY view), 2) as percentage_by_view,\n",
        "        ROUND(AVG(age), 1) as avg_age\n",
        "    FROM covid_data\n",
        "    GROUP BY view, finding_unified\n",
        "    ORDER BY view, count_images DESC\n",
        "\"\"\")\n",
        "\n",
        "query5.show(20, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Фильтрация и сохранение данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Фильтрация: только COVID-19 пациенты старше 18 лет\n",
        "filtered_df = df.where((col(\"finding_unified\") == \"COVID-19\") & (col(\"age\") >= 18))\n",
        "\n",
        "print(f'Всего записей: {df.count()}')\n",
        "print(f'После фильтрации (COVID-19, вік ≥ 18): {filtered_df.count()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохранение в оптимизированном формате Parquet\n",
        "filtered_df.write.mode(\"overwrite\").parquet('covid19_filtered')\n",
        "\n",
        "# Проверка сохраненных данных\n",
        "spark.read.parquet('covid19_filtered').show(20, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Визуализация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Конвертация в Pandas для визуализации\n",
        "df_pandas = df.toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1. Круговая диаграмма распределения диагнозов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "df_pandas['finding_unified'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90)\n",
        "plt.ylabel('')\n",
        "plt.title('Распределение диагнозов', fontsize=16, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2. Столбчатая диаграмма по возрастным группам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "age_dist = df_pandas['age_category'].value_counts().sort_index()\n",
        "ax = age_dist.plot(kind='bar', color='steelblue')\n",
        "plt.xlabel('Возрастная группа', fontsize=12)\n",
        "plt.ylabel('Количество пациентов', fontsize=12)\n",
        "plt.title('Распределение пациентов по возрастным группам', fontsize=16)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Добавляем значения на столбцы\n",
        "for i, v in enumerate(age_dist):\n",
        "    ax.text(i, v + 5, str(v), ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3. График временных трендов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Подготовка данных для графика\n",
        "time_data = query4.toPandas()\n",
        "time_data = time_data[time_data['year'] >= 2019]  # Фильтруем данные с 2019 года\n",
        "time_data['date'] = pd.to_datetime(time_data[['year', 'month']].assign(day=1))\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(time_data['date'], time_data['count_studies'], marker='o', linewidth=2, markersize=6)\n",
        "plt.xlabel('Дата', fontsize=12)\n",
        "plt.ylabel('Количество исследований', fontsize=12)\n",
        "plt.title('Временные тренды количества исследований', fontsize=16)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.4. Heatmap распределения диагнозов по проекциям"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Подготовка данных для heatmap\n",
        "pivot_data = df_pandas.groupby(['view', 'finding_unified']).size().unstack(fill_value=0)\n",
        "\n",
        "# Берем топ-5 проекций и диагнозов для читабельности\n",
        "top_views = df_pandas['view'].value_counts().head(5).index\n",
        "top_findings = df_pandas['finding_unified'].value_counts().head(5).index\n",
        "pivot_data_filtered = pivot_data.loc[top_views, top_findings]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(pivot_data_filtered, annot=True, fmt='d', cmap='YlOrRd', cbar_kws={'label': 'Количество'})\n",
        "plt.xlabel('Диагноз', fontsize=12)\n",
        "plt.ylabel('Проекция снимка', fontsize=12)\n",
        "plt.title('Распределение диагнозов по проекціях снімків', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Выводы\n",
        "\n",
        "На основе проведенного анализа можно сделать следующие выводы:\n",
        "\n",
        "1. **Распределение диагнозов**: Большинство пациентов в датасете имеют диагноз COVID-19, что соответствует тематике исследования.\n",
        "\n",
        "2. **Возрастная структура**: Анализ показал, что среди пациентов с COVID-19 преобладают лица среднего и пожилого возраста (45+ лет), что согласуется с эпидемиологическими данными о группах риска.\n",
        "\n",
        "3. **Гендерное распределение**: Выявлены определенные различия в распределении диагнозов между мужчинами и женщинами, что может указывать на различную склонность к разным респираторным заболеваниям.\n",
        "\n",
        "4. **Временные тренды**: Выявлены сезонные колебания количества исследований, с пиком в определенные месяцы, что может быть связано с волнами пандемии.\n",
        "\n",
        "5. **Технические аспекты**: Наиболее распространенные проекции снимков (PA, AP) коррелируют с определенными типами диагнозов, что может быть полезно для оптимизации диагностических процедур."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Закрытие Spark сессии\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
